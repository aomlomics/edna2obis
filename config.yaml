# edna2obis Configuration File
# This is an example of a config file for a FAIRe NOAA / ODE Formatted dataset
# USERS: Please edit the config.yaml file, not this one. This is just a template.
# Here, you specify where all of your data is, set a few other parameters, and set parameters related to the taxonomic assignment.

# STEP 1
# --- OPTIONAL: Specify a path to a different config file for the run ---
# If you want to use a config file other than this default 'config.yaml',
# you can specify its path here. The pipeline will then load that file.
# If left blank or set to 'config.yaml', this file will be used.
run_config_path: "config.yaml"
metadata_format: "NOAA"  # "NOAA" or "GENERIC". NOAA format has separate analysisMetadata sheets. GENERIC format has analysis data within projectMetadata.
edna2obis_run_name: "Whale_Prey_Taxa_Testing_20251015" # This name will be used to name your config file (outputted for your convenience after your run is complete)
# This name will also be used to name your HTML report and Taxa assignment INFO files.

# STEP 2: Metadata source — true = You have one Excel file, with all your metadata as seperate sheets in the same Excel file. 
# false = You have separate TSV files, one for each metadata sheet.
# Set to true or false; you can keep both sets of paths below. Only the chosen one is read.
combined_metadata_file: false

# When combined_metadata_file: true — single Excel file and sheet names
sampleMetadata: "sampleMetadata"
experimentRunMetadata: "experimentRunMetadata"
projectMetadata: "projectMetadata"
excel_file: "raw-v3/FAIRe_NOAA_example_dataset/FAIRe-NOAA_noaa-sefsc-gu1901.xlsx"

# When combined_metadata_file: false — separate TSV files (one path per sheet)
sampleMetadata_file: "raw-v3/FAIRe_NOAA_example_dataset_lib_id_abundance/FAIRe_noaa-sefsc-gu1901-sampleMetadata.tsv"
experimentRunMetadata_file: "raw-v3/FAIRe_NOAA_example_dataset_lib_id_abundance/FAIRe_noaa-sefsc-gu1901-experimentRunMetadata.tsv"
projectMetadata_file: "raw-v3/FAIRe_NOAA_example_dataset_lib_id_abundance/FAIRe_noaa-sefsc-gu1901-projectMetadata.tsv"

# STEP 3
# Assign pathnames for your raw data. Each analysis must have 2 raw data files associated with it.
# For NOAA format with TSV analysisMetadata files, also include 'analysisMetadata_file' for each run.
# If your metadata sheets are all in the same Excel file, you do NOT need to include 'analysisMetadata_file' for each run.
datafiles:
  rosel-ctd-mifish-addMFtrawlJfish-241001: #analysis_run_name
    assay_name: "Fish-12S-MiFish-Miya-Stoeckle"
    taxonomy_file: "raw-v3/FAIRe_NOAA_example_dataset_lib_id_abundance/asvTaxaFeatures_gu1901_mifish_addMFtrawlJfish_v2024.10_241001.tsv"
    occurrence_file: "raw-v3/FAIRe_NOAA_example_dataset_lib_id_abundance/table_gu1901_mifish_addMFtrawlJfish_v2024.10_241001.tsv"
    analysisMetadata_file: "raw-v3/FAIRe_NOAA_example_dataset_lib_id_abundance/analysisMetadata_gu1901_mifish_addMFtrawlJfish_v2024.10_241001.tsv"
  rosel-ctd-riaz-addMFtrawlJfish-241001: #analysis_run_name
    assay_name: "Fish-12S-Riaz"
    taxonomy_file: "raw-v3/FAIRe_NOAA_example_dataset/asvTaxaFeatures_addJ-riaz_sefsc-gu1901.tsv"
    occurrence_file: "raw-v3/FAIRe_NOAA_example_dataset/table_addJ-riaz_sefsc-gu1901.tsv"
    # analysisMetadata_file: "path/to/analysisMetadata_rosel-ctd-riaz-addMFtrawlJfish-241001.tsv"

  # Add other analysis runs here, following the pattern:
  # your_analysis_run_name:
  #   assay_name: "your_assay_name_from_projectMetadata_column"
  #   taxonomy_file: "path/to/your/asvTaxaFeatures_your_analysis_run_name.tsv"
  #   occurrence_file: "path/to/your/table_your_analysis_run_name.tsv"
  #   analysisMetadata_file: "path/to/analysisMetadata_your_analysis_run_name.tsv" 


# STEP 4:
# Sample filtering configuration
# Control sample detection - specify the column to check and which values indicate control samples
control_sample_detection:
  column_name: "samp_category"  # Column name to check for control indicators
  control_values:               # List of values in that column that indicate control samples
    - "negative control"
    - "positive control"

# STEP 5:
# The pipeline will construct the Darwin Core 'locationID' based on the following priority:
# 1. It will first look for a column literally named 'locationID' in your sampleMetadata. If found, it will be used directly.
# 2. If not found, it will use the list of columns you define below to create a compound ID (e.g., columnA_columnB).
# 3. If this section is missing or empty, it will default to combining 'line_id' and 'station_id'.
locationID_components:
  - line_id
  - station_id

# -----------------------------------------------------------------------------
# Taxonomic Assignment Parameters
# -----------------------------------------------------------------------------

# STEP 6:
# Specify which API you would like to use to assign taxonomy. Options are either WoRMS or GBIF
# Taxonomic Assignment Parameters:
# taxonomic_api_source: "GBIF"
taxonomic_api_source: "WoRMS"

# Define the maximum number of matches to request from the GBIF API for each unique taxonomy string.
# A higher number may provide more potential matches for review but will SIGNIFICANTLY increase processing time.
gbif_match_limit: 3

# STEP 7:
# Define which assays should not consider 'species' rank in their taxonomic assignment.
# This is because certain assays (for example, 16S) species' level assignments are not useful / correct.
# Additionally, for example, 18S species' level assignments are good, and we want them!
# This should be the exact 'assay_name' value as found in your analysisMetadata sheets (cell D3)
# and subsequently in the 'assay_name' column of the intermediate occurrence.csv
assays_to_skip_species_match:
  # - "ssu16sv4v5-emp"  # Example, replace with your actual assay names, comment out if you want species-level to be used in taxonomic assignment
  # - "another_16s_assay_name_if_any"

# Optional local reference database (WoRMS only) - speeds up matching significantly!
use_local_reference_database: false  # or false  
local_reference_database_path: "raw-v3/pr2_version_5.0.0_taxonomy.xlsx"

# Optional parameters (will use defaults if not specified)
# Number of processes for matching (0 means use all available CPUs)
worms_n_proc: 0
gbif_n_proc: 0

# Output directory (will be created if it doesn't exist)
output_dir: "processed-v3/"

# STEP 8: OPTIONAL output files
# -----------------------------------------------------------------------------
# OPTIONAL Output Files: eMoF (extended measurement or fact), and EML (Ecological Metadata Language)
# Data for these files must be manually entered in their respective input files:
# eMoF: raw-v3/eMoF Fields edna2obis .xlsx
# EML: EML_config.yaml
# -----------------------------------------------------------------------------
# Enable/disable eMoF creation. Set to true to get an eMoF, false to skip eMoF output.
emof_enabled: true
emof_template_path: "raw-v3/eMoF_Fields_edna2obis.tsv"
# Optional: path to the eMoF template Excel. If not provided, defaults to raw-v3/eMoF_Fields_edna2obis.xlsx

# Enable/disable EML creation. Set to true to generate EML XML file, false to skip.
# EML metadata configuration is stored in a separate file (see eml_config_path below)
eml_enabled: true
eml_config_path: "EML_config.yaml"

# STEP 9: OPTIONAL - Split output files by cruise/expedition (short_name)
# -----------------------------------------------------------------------------
# If your sampleMetadata contains a 'short_name' column (cruise/expedition codes),
# you can split the final output files into separate subfolders per short_name.
# This is useful when databases require cruise-by-cruise submissions connected by a parent project.
# 
# When enabled:
#   - Creates subfolders: {output_dir}/{short_name}/
#   - Saves filtered files with suffix: occurrence_core_{api}_{short_name}.csv
#   - Splits: occurrence_core, dna_derived_extension, eMoF
#   - Does NOT split: HTML report, taxa_assignment_INFO
#
# IMPORTANT: If enabled, ALL samples in sampleMetadata MUST have a short_name value.
#            Missing values will cause an error.
split_output_by_short_name: false